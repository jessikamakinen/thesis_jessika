{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Communication round 1/50\n",
      "Test loss: 2.2610, Accuracy: 14.68%\n",
      "\n",
      "Communication round 2/50\n",
      "Test loss: 2.0581, Accuracy: 24.30%\n",
      "\n",
      "Communication round 3/50\n",
      "Test loss: 1.9453, Accuracy: 27.94%\n",
      "\n",
      "Communication round 4/50\n",
      "Test loss: 1.8436, Accuracy: 31.63%\n",
      "\n",
      "Communication round 5/50\n",
      "Test loss: 1.7379, Accuracy: 35.24%\n",
      "\n",
      "Communication round 6/50\n",
      "Test loss: 1.7029, Accuracy: 37.77%\n",
      "\n",
      "Communication round 7/50\n",
      "Test loss: 1.6659, Accuracy: 38.32%\n",
      "\n",
      "Communication round 8/50\n",
      "Test loss: 1.6211, Accuracy: 40.57%\n",
      "\n",
      "Communication round 9/50\n",
      "Test loss: 1.5851, Accuracy: 42.77%\n",
      "\n",
      "Communication round 10/50\n",
      "Test loss: 1.5666, Accuracy: 42.81%\n",
      "\n",
      "Communication round 11/50\n",
      "Test loss: 1.5409, Accuracy: 44.17%\n",
      "\n",
      "Communication round 12/50\n",
      "Test loss: 1.5442, Accuracy: 43.65%\n",
      "\n",
      "Communication round 13/50\n",
      "Test loss: 1.4969, Accuracy: 45.37%\n",
      "\n",
      "Communication round 14/50\n",
      "Test loss: 1.4994, Accuracy: 45.81%\n",
      "\n",
      "Communication round 15/50\n",
      "Test loss: 1.4793, Accuracy: 46.84%\n",
      "\n",
      "Communication round 16/50\n",
      "Test loss: 1.4606, Accuracy: 46.66%\n",
      "\n",
      "Communication round 17/50\n",
      "Test loss: 1.4463, Accuracy: 48.26%\n",
      "\n",
      "Communication round 18/50\n",
      "Test loss: 1.4417, Accuracy: 47.41%\n",
      "\n",
      "Communication round 19/50\n",
      "Test loss: 1.4390, Accuracy: 48.08%\n",
      "\n",
      "Communication round 20/50\n",
      "Test loss: 1.4240, Accuracy: 48.71%\n",
      "\n",
      "Communication round 21/50\n",
      "Test loss: 1.4317, Accuracy: 48.15%\n",
      "\n",
      "Communication round 22/50\n",
      "Test loss: 1.4178, Accuracy: 48.47%\n",
      "\n",
      "Communication round 23/50\n",
      "Test loss: 1.4225, Accuracy: 48.23%\n",
      "\n",
      "Communication round 24/50\n",
      "Test loss: 1.4357, Accuracy: 47.63%\n",
      "\n",
      "Communication round 25/50\n",
      "Test loss: 1.3891, Accuracy: 49.98%\n",
      "\n",
      "Communication round 26/50\n",
      "Test loss: 1.4095, Accuracy: 49.26%\n",
      "\n",
      "Communication round 27/50\n",
      "Test loss: 1.4131, Accuracy: 48.29%\n",
      "\n",
      "Communication round 28/50\n",
      "Test loss: 1.3940, Accuracy: 49.95%\n",
      "\n",
      "Communication round 29/50\n",
      "Test loss: 1.4189, Accuracy: 48.84%\n",
      "\n",
      "Communication round 30/50\n",
      "Test loss: 1.3995, Accuracy: 50.01%\n",
      "\n",
      "Communication round 31/50\n",
      "Test loss: 1.4013, Accuracy: 49.51%\n",
      "\n",
      "Communication round 32/50\n",
      "Test loss: 1.3877, Accuracy: 50.36%\n",
      "\n",
      "Communication round 33/50\n",
      "Test loss: 1.4127, Accuracy: 49.23%\n",
      "\n",
      "Communication round 34/50\n",
      "Test loss: 1.3922, Accuracy: 50.55%\n",
      "\n",
      "Communication round 35/50\n",
      "Test loss: 1.4214, Accuracy: 48.94%\n",
      "\n",
      "Communication round 36/50\n",
      "Test loss: 1.4415, Accuracy: 48.37%\n",
      "\n",
      "Communication round 37/50\n",
      "Test loss: 1.3828, Accuracy: 50.42%\n",
      "\n",
      "Communication round 38/50\n",
      "Test loss: 1.3820, Accuracy: 50.65%\n",
      "\n",
      "Communication round 39/50\n",
      "Test loss: 1.4076, Accuracy: 49.35%\n",
      "\n",
      "Communication round 40/50\n",
      "Test loss: 1.4305, Accuracy: 47.98%\n",
      "\n",
      "Communication round 41/50\n",
      "Test loss: 1.4069, Accuracy: 49.41%\n",
      "\n",
      "Communication round 42/50\n",
      "Test loss: 1.3991, Accuracy: 50.48%\n",
      "\n",
      "Communication round 43/50\n",
      "Test loss: 1.3829, Accuracy: 51.11%\n",
      "\n",
      "Communication round 44/50\n",
      "Test loss: 1.4318, Accuracy: 49.21%\n",
      "\n",
      "Communication round 45/50\n",
      "Test loss: 1.3993, Accuracy: 49.41%\n",
      "\n",
      "Communication round 46/50\n",
      "Test loss: 1.3817, Accuracy: 51.15%\n",
      "\n",
      "Communication round 47/50\n",
      "Test loss: 1.4014, Accuracy: 50.59%\n",
      "\n",
      "Communication round 48/50\n",
      "Test loss: 1.4070, Accuracy: 49.44%\n",
      "\n",
      "Communication round 49/50\n",
      "Test loss: 1.4089, Accuracy: 49.16%\n",
      "\n",
      "Communication round 50/50\n",
      "Test loss: 1.4205, Accuracy: 49.34%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class MyCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss(reduction='sum')(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    return test_loss / len(test_loader.dataset), correct / len(test_loader.dataset)\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = OrderedDict()\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([client_weights[key] for client_weights in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "    \n",
    "def create_client_dataset(dataset, num_clients):\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "    client_indices = np.array_split(indices, num_clients)\n",
    "    client_datasets = [Subset(dataset, index_list) for index_list in client_indices]\n",
    "    return client_datasets\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "num_clients = 5\n",
    "client_datasets = create_client_dataset(train_dataset, num_clients)\n",
    "train_loaders = [DataLoader(client_dataset, batch_size=100, shuffle=True) for client_dataset in client_datasets]\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "def federated_learning(train_loaders, test_loader, device, epochs, num_clients, communication_rounds, client_weighting, clients_per_round):\n",
    "    global_model = MyCNNModel().to(device)\n",
    "    client_models = [MyCNNModel().to(device) for _ in range(num_clients)]\n",
    "\n",
    "    for client_model in client_models:\n",
    "        client_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    for com_round in range(1, communication_rounds + 1):\n",
    "        print(f'Communication round {com_round}/{communication_rounds}')\n",
    "\n",
    "        selected_clients = np.random.choice(range(num_clients), size=clients_per_round, replace=False)\n",
    "        client_weights = []\n",
    "\n",
    "        for idx in selected_clients:\n",
    "            client_model = client_models[idx]\n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=0.01, momentum=0.9)\n",
    "            train_model(client_model, device, train_loaders[idx], optimizer, epochs)\n",
    "\n",
    "            client_weight = client_weighting[idx] if client_weighting else 1\n",
    "            weighted_client_state = OrderedDict()\n",
    "\n",
    "            for key in client_model.state_dict().keys():\n",
    "                weighted_client_state[key] = client_model.state_dict()[key] * client_weight\n",
    "\n",
    "            client_weights.append(weighted_client_state)\n",
    "\n",
    "        global_weights = average_weights(client_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        test_loss, accuracy = test_model(global_model, device, test_loader)\n",
    "        print(f'Test loss: {test_loss:.4f}, Accuracy: {accuracy * 100:.2f}%\\n')\n",
    "\n",
    "    return global_model\n",
    "\n",
    "communication_rounds = 50\n",
    "client_weighting = [1, 1, 1, 1, 1]  # Equal weighting for all clients\n",
    "clients_per_round = 5\n",
    "\n",
    "federated_model = federated_learning(train_loaders, test_loader, device, epochs, num_clients, communication_rounds, client_weighting, clients_per_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('jessVIT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf8fa5aea382284d3485dc5460c54fd3d5550fab184fdf72c2e9b70f5312d5ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
