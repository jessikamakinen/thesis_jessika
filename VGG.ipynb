{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 16:34:43.687583: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-09 16:34:43.687636: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 16:34:51.907081: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-09 16:34:51.908133: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-09 16:34:51.908168: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-09 16:34:51.908196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gaia-XPS-13-9310): /proc/driver/nvidia/version does not exist\n",
      "2023-04-09 16:34:51.908829: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 16:34:51.909659: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 17s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 16:35:09.832567: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-04-09 16:35:09.901441: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-04-09 16:35:09.921056: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-04-09 16:35:11.626757: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2023-04-09 16:35:13.289557: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-04-09 16:35:13.311052: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2803200000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 16:35:13.650044: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 290s 740ms/step - loss: 1.6005 - accuracy: 0.4437 - val_loss: 1.2809 - val_accuracy: 0.5512\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 307s 786ms/step - loss: 1.2679 - accuracy: 0.5509 - val_loss: 1.1841 - val_accuracy: 0.5849\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 497s 1s/step - loss: 1.1958 - accuracy: 0.5785 - val_loss: 1.1665 - val_accuracy: 0.5936\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 540s 1s/step - loss: 1.1636 - accuracy: 0.5925 - val_loss: 1.1546 - val_accuracy: 0.5983\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 498s 1s/step - loss: 1.1381 - accuracy: 0.6014 - val_loss: 1.1319 - val_accuracy: 0.6058\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 607s 2s/step - loss: 1.1081 - accuracy: 0.6074 - val_loss: 1.1347 - val_accuracy: 0.6119\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 795s 2s/step - loss: 1.0761 - accuracy: 0.6181 - val_loss: 1.1238 - val_accuracy: 0.6072\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 611s 2s/step - loss: 1.0522 - accuracy: 0.6282 - val_loss: 1.1062 - val_accuracy: 0.6232\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 399s 1s/step - loss: 1.0330 - accuracy: 0.6340 - val_loss: 1.1036 - val_accuracy: 0.6165\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 335s 858ms/step - loss: 1.0099 - accuracy: 0.6435 - val_loss: 1.1088 - val_accuracy: 0.6163\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 337s 863ms/step - loss: 0.9945 - accuracy: 0.6457 - val_loss: 1.0986 - val_accuracy: 0.6214\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 372s 953ms/step - loss: 0.9662 - accuracy: 0.6616 - val_loss: 1.1007 - val_accuracy: 0.6232\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 361s 923ms/step - loss: 0.9609 - accuracy: 0.6597 - val_loss: 1.0879 - val_accuracy: 0.6301\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 349s 893ms/step - loss: 0.9292 - accuracy: 0.6696 - val_loss: 1.0815 - val_accuracy: 0.6233\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 365s 934ms/step - loss: 0.9192 - accuracy: 0.6755 - val_loss: 1.0808 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 376s 962ms/step - loss: 0.8907 - accuracy: 0.6828 - val_loss: 1.0873 - val_accuracy: 0.6319\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 372s 951ms/step - loss: 0.8919 - accuracy: 0.6790 - val_loss: 1.0808 - val_accuracy: 0.6325\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 373s 953ms/step - loss: 0.8620 - accuracy: 0.6900 - val_loss: 1.0806 - val_accuracy: 0.6325\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 359s 919ms/step - loss: 0.8726 - accuracy: 0.6887 - val_loss: 1.0838 - val_accuracy: 0.6318\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 370s 946ms/step - loss: 0.8478 - accuracy: 0.6954 - val_loss: 1.0876 - val_accuracy: 0.6352\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 390s 997ms/step - loss: 0.8273 - accuracy: 0.7033 - val_loss: 1.0747 - val_accuracy: 0.6386\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 396s 1s/step - loss: 0.8122 - accuracy: 0.7093 - val_loss: 1.0868 - val_accuracy: 0.6353\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 433s 1s/step - loss: 0.8005 - accuracy: 0.7113 - val_loss: 1.0793 - val_accuracy: 0.6382\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 449s 1s/step - loss: 0.7905 - accuracy: 0.7185 - val_loss: 1.0930 - val_accuracy: 0.6372\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 507s 1s/step - loss: 0.7889 - accuracy: 0.7150 - val_loss: 1.1035 - val_accuracy: 0.6294\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 528s 1s/step - loss: 0.7626 - accuracy: 0.7287 - val_loss: 1.0972 - val_accuracy: 0.6380\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 541s 1s/step - loss: 0.7530 - accuracy: 0.7305 - val_loss: 1.0975 - val_accuracy: 0.6278\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 513s 1s/step - loss: 0.7420 - accuracy: 0.7327 - val_loss: 1.0980 - val_accuracy: 0.6376\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 539s 1s/step - loss: 0.7355 - accuracy: 0.7369 - val_loss: 1.0990 - val_accuracy: 0.6369\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1057s 3s/step - loss: 0.7080 - accuracy: 0.7457 - val_loss: 1.1036 - val_accuracy: 0.6369\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1020s 3s/step - loss: 0.7119 - accuracy: 0.7422 - val_loss: 1.1130 - val_accuracy: 0.6359\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 793s 2s/step - loss: 0.7007 - accuracy: 0.7481 - val_loss: 1.1065 - val_accuracy: 0.6363\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 460s 1s/step - loss: 0.6959 - accuracy: 0.7469 - val_loss: 1.1108 - val_accuracy: 0.6377\n",
      "Epoch 34/50\n",
      " 47/391 [==>...........................] - ETA: 5:50 - loss: 0.6811 - accuracy: 0.7543"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers to model\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('jessThesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba3e593dfa68b70bdebf21461047a975a5aa7a97a5a84511d36f2c608b121581"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
